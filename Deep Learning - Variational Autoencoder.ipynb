{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder\n",
    "\n",
    "Variational Autoencoders (VAEs) are dimensionality reduction devices that code inputs into the latent parameters of a statistical process that supposedly gave rise to them. In practice, this is typically a normal distribution. The decoding involves sampling from the statistical distribution with a given latent parameter and chasing the result through a decoder network.\n",
    "\n",
    "The difference to classical autoencoders is that variational autoencoders map an input to a function (the distribution) and classical autoencoders map an input to a vector. \n",
    "\n",
    "c.f. this exellent post https://github.com/yaniv256/VAEs-in-Economics/blob/master/Notebooks/One_Dimensional_VAE_Workshop.ipynb\n",
    "\n",
    "which uses Chapter 8 in http://faculty.neu.edu.cn/yury/AAI/Textbook/Deep%20Learning%20with%20Python.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU test\n",
      "Executing basic TF graph on GPU:0\n",
      "Success.\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n",
      "GPUs found:\n",
      "[0]\tPhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "\n",
    "def gpu_test():\n",
    "    print(\"GPU test\")\n",
    "    with tf.device('GPU:0'):\n",
    "        print(\"Executing basic TF graph on GPU:0\")\n",
    "        a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "        b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "        c = tf.matmul(a, b)\n",
    "        print(\"Success.\")\n",
    "        print(c)\n",
    "        print(\"GPUs found:\")\n",
    "        physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "        print('\\n'.join('[%i]\\t'%i +str(dev) for i,dev in enumerate(physical_devices)))\n",
    "\n",
    "gpu_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from src.resourcelims import memory\n",
    "\n",
    "\"\"\"\n",
    "Check GPU \n",
    "\"\"\"\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "from keras import backend\n",
    "\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "#tf.config.experimental_run_functions_eagerly(True)\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "\n",
    "\n",
    "@memory(0.8)\n",
    "def gpu_test():\n",
    "    \n",
    "    print(\"TENSORFLOW\")\n",
    "    with tf.device('GPU:0'):\n",
    "        \n",
    "        a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "        b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "        c = tf.matmul(a, b)\n",
    "        \n",
    "    print(c)\n",
    "    #print(\"LOCAL DEVICES\",device_lib.list_local_devices())\n",
    "    print(\"PHYSICAL DEVICES\")\n",
    "    print('\\n'.join([str(x) for x in tf.config.list_physical_devices()]))\n",
    "\n",
    "    #print(backend.tensorflow_backend._get_available_gpus())\n",
    "\n",
    "gpu_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 28, 28, 16)   160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 32)   4640        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 14, 32)   9248        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 32)   9248        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 6272)         0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           100368      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            34          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            34          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 2)            0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "functional_1 (Functional)       (None, 28, 28, 1)    28353       lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "custom_variational_layer (Custo (None, 28, 28, 1)    0           input_1[0][0]                    \n",
      "                                                                 functional_1[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 152,085\n",
      "Trainable params: 152,085\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import backend as K \n",
    "from keras.models import Model \n",
    "from keras.datasets import mnist\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "img_shape = (28, 28, 1)\n",
    "batch_size = 16\n",
    "latent_dim = 2\n",
    "\n",
    "#@memory(0.8)\n",
    "def make_model():\n",
    "\n",
    "    with tf.device('GPU:0'):\n",
    "        \"\"\"\n",
    "        Encoder\n",
    "        \"\"\"\n",
    "        input_img = keras.Input(shape=img_shape)\n",
    "        \n",
    "        x = layers.Conv2D(16, 3, padding='same', activation='relu')(input_img)\n",
    "        x = layers.Conv2D(32, 3, padding='same', activation='relu', strides=(2, 2))(x)\n",
    "        x = layers.Conv2D(32, 3, padding='same', activation='relu')(x) \n",
    "        x = layers.Conv2D(32, 3, padding='same', activation='relu')(x) \n",
    "\n",
    "        #x = layers.Conv2D(32, 3, padding='same', activation='relu')(input_img)\n",
    "        #x = layers.Conv2D(64, 3, padding='same', activation='relu', strides=(2, 2))(x) \n",
    "        #x = layers.Conv2D(64, 3, padding='same', activation='relu')(x) \n",
    "        #x = layers.Conv2D(64, 3, padding='same', activation='relu')(x) \n",
    "\n",
    "        shape_before_flattening = K.int_shape(x)\n",
    "\n",
    "        x = layers.Flatten()(x)\n",
    "        \n",
    "        #x = layers.Dense(32, activation='relu')(x)\n",
    "        x = layers.Dense(16, activation='relu')(x)\n",
    "\n",
    "        # encoder output (latent parameters)\n",
    "        z_mean = layers.Dense(latent_dim)(x) \n",
    "        z_log_var = layers.Dense(latent_dim)(x)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Sampling\n",
    "        \"\"\"\n",
    "        def sampling(args):\n",
    "            z_mean, z_log_var = args\n",
    "            epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "            mean=0., stddev=1.) \n",
    "            return z_mean + K.exp(z_log_var) * epsilon\n",
    "\n",
    "        # sample from latent distribution\n",
    "        z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Decoder\n",
    "        \"\"\"\n",
    "        decoder_input = layers.Input(K.int_shape(z)[1:])\n",
    "        x = layers.Dense(np.prod(shape_before_flattening[1:]), activation='relu')(decoder_input)\n",
    "        x = layers.Reshape(shape_before_flattening[1:])(x)\n",
    "        x = layers.Conv2DTranspose(32, 3, padding='same', activation='relu', strides=(2, 2))(x)\n",
    "        x = layers.Conv2D(1, 3, padding='same', activation='sigmoid')(x)\n",
    "\n",
    "        decoder = Model(decoder_input, x)\n",
    "\n",
    "        # decoder output\n",
    "        z_decoded = decoder(z)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Custom Loss\n",
    "        \"\"\"\n",
    "\n",
    "        class CustomVariationalLayer(keras.layers.Layer):\n",
    "\n",
    "            def vae_loss(self, x, z_decoded): \n",
    "                x = K.flatten(x)\n",
    "                z_decoded = K.flatten(z_decoded)\n",
    "\n",
    "                # reconstruction loss\n",
    "                xent_loss = keras.metrics.binary_crossentropy(x, z_decoded) \n",
    "\n",
    "                # regularization loss\n",
    "                kl_loss = -5e-4 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1) \n",
    "\n",
    "                return K.mean(xent_loss + kl_loss)\n",
    "\n",
    "            def call(self, inputs):\n",
    "                x = inputs[0]\n",
    "                z_decoded = inputs[1]\n",
    "                loss = self.vae_loss(x, z_decoded) \n",
    "                self.add_loss(loss, inputs=inputs) \n",
    "                return x\n",
    "\n",
    "        # loss \n",
    "        y = CustomVariationalLayer()([input_img, z_decoded])\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Training (on MNIST)\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "\n",
    "        # compile model (input; loss)\n",
    "        vae = Model(input_img, y) \n",
    "        vae.compile(optimizer='rmsprop', loss=None) \n",
    "        \n",
    "        return vae\n",
    "\n",
    "vae = make_model()        \n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpbm/.pyenv/versions/3.8.5/envs/occrp/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:3349: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 338/3750 [=>............................] - ETA: 11:22 - loss: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "from src.resourcelims import memory\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "#@memory(0.90)\n",
    "def train():\n",
    "    with tf.device('GPU:0'):\n",
    "        (x_train, _), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        x_train = x_train.astype('float32') / 255. \n",
    "        x_train = x_train.reshape(x_train.shape + (1,)) \n",
    "\n",
    "        x_test = x_test.astype('float32') / 255.\n",
    "        x_test = x_test.reshape(x_test.shape + (1,))\n",
    "\n",
    "        vae.fit(x=x_train, y=None, shuffle=True,\n",
    "                epochs=10,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(x_test, None))\n",
    "    return vae\n",
    "\n",
    "vae = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error is due to incompatibility in cuda, cudnn and Nvidia drivers or memory growth issue. The memory growth issue should be addressed so it's the former issues, most likely. TO DO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8*32*28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

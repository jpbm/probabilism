% \chapauthor{J. P. Balthasar Mueller}
\chapter{Linear Algebra and Multivariable Calculus}

\begin{multicols}{2}[\subsubsection*{Contents of this chapter}]
   \printcontents{}{1}{\setcounter{tocdepth}{2}}
\end{multicols}



\section{Multi-Index Notation}
Multi-index notation makes high-dimensional things faster and easier. A collection is indices is represented by a tuple $\alpha = \left(\alpha_1,\alpha_2,\alpha_3,... \right)$. The absolute value $|\alpha| = \sum_i \alpha$, partial derivatives $\partial^\alpha = \prod \partial^{\alpha_i}$, powers $\mathbf{x}^\alpha = \prod_i x_i^{\alpha_i}$.

\subsubsection{Multinomial Coefficients}	

Instead of:
\begin{equation}
\sum_{0\leq i_1,i_2,i_3,...,i_k \leq n} {n \choose i_1,i_2,i_3,...,i_k} 
\end{equation}

Write:

\begin{equation}	
\sum_{0\leq |\alpha|\leq n}{n \choose \alpha}
\end{equation}

\subsubsection{Taylor Expansion}

For a vector valued function $\mathbf{f}: \mathbb{R}^n \rightarrow \mathbb{R}^m$ that is analytical in a neighborhood of the point $\mathbf{a}$:

\begin{equation}
f(\mathbf{x}) = \sum_{|\alpha|\geq0} \frac{(\mathbf{x} - \mathbf{a})^\alpha}{\alpha!}(\partial^\alpha)f
\end{equation}



% Cholesky Decomposition
\section{$\mathbf{A} = \mathbf{L}\mathbf{L}^{\dagger}$ Cholesky Decomposition}
\label{sec:cholesky}

The Cholesky Decomposition exists when a matrix is hermitian and positive-definite. It expresses the matrix $\mathbf{A}$ as:

\begin{equation}
\mathbf{A} = \mathbf{L}\mathbf{L^\dagger}
\end{equation}

Where $\mathbf{L}$ is a lower-triangular matrix with positive, real diagonal entries. When $\mathbf{A}$ is real, then so is $\mathbf{L}$. The Cholesky decomposition enables fast solution of a linear system, but it can also be used to create correlated random variables in Monte Carlo simulations. 

\subsubsection{Creating Correlated Random Variables}
Let $\mathbf{u}_t$ be a vector of uncorrelated samples with mean 0 and 	standard deviation 1. If the covariance matrix of the system to be simulated is  $\mathbf{\Sigma}$ with Cholesky decomposition $\mathbf{\Sigma} = \mathbf{LL}^\dagger$, then the vector $\mathbf{v}_t = \mathbf{Lu}_t$ has the desired covariance.

\begin{figure}
\centering
\includegraphics[scale=0.5]{cholesky1.png}
\includegraphics[scale=0.5]{cholesky2.png}
\caption{Creating correlated random variables from uncorrelated random variables using the Cholesky decomposition of the covariance matrix. The 5 uncorrelated random variables are sampled from a standard normal distribution. It is difficult to see a difference between the correlated and uncorrelated random walks.}
\end{figure}



\section{Generalized Eigenvectors}

\input{./chapters/sections/linalg_spectral.tex}
\input{./chapters/sections/linalg_svd.tex}
\input{./chapters/sections/linalg_transformations.tex}
\input{./chapters/sections/linalg_matrixtypes.tex}
\input{./chapters/sections/linalg_norms.tex}
\input{./chapters/sections/linalg_diff.tex}



\chapauthor{}

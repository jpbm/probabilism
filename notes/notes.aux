\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\ttl@writefile{ptc}{\ttl@starttoc{default@1}}
\citation{stanfordsetnotation}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Sets and Measure Theory }{11}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@1}}
\ttl@writefile{ptc}{\ttl@starttoc{default@2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Representation}{12}{section.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Set Properties and Types of Sets}{12}{section.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Cardinality}{12}{subsection.1.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}$\emptyset $ Empy Set, Null Set}{12}{subsection.1.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Singleton Set}{12}{subsection.1.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}Countable Sets}{12}{subsection.1.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.5}Infinite Sets}{12}{subsection.1.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.6}Multisets}{12}{subsection.1.2.6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.6.1}Support}{12}{subsubsection.1.2.6.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.6.2}Cardinality}{12}{subsubsection.1.2.6.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.6.3}$\subseteq $ Inclusion}{13}{subsubsection.1.2.6.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.6.4}$\DOTSB \bigcap@ \slimits@ $ Intersection}{13}{subsubsection.1.2.6.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.6.5}$\DOTSB \bigcup@ \slimits@ $ Union}{13}{subsubsection.1.2.6.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.6.6}$\uplus $ Multiset Addition}{13}{subsubsection.1.2.6.6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.6.7}Multiset Subtraction}{13}{subsubsection.1.2.6.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.7}Powersets}{13}{subsection.1.2.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.8}Measurable Sets}{13}{subsection.1.2.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.9}Universal Set}{14}{subsection.1.2.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.10}Open Sets, Closed Sets}{14}{subsection.1.2.10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.10.1}Interior Points}{14}{subsubsection.1.2.10.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.10.2}Accumulation Points}{14}{subsubsection.1.2.10.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.10.3}Open Sets}{14}{subsubsection.1.2.10.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.10.4}Closed Sets}{14}{subsubsection.1.2.10.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.10.5}Both Open and Closed, Neither Open Nor Closed}{14}{subsubsection.1.2.10.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.11}Image}{14}{subsection.1.2.11}}
\newlabel{sec:image}{{1.2.11}{14}{Image}{subsection.1.2.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.12}Preimage, Inverse Image}{14}{subsection.1.2.12}}
\newlabel{sec:preimage}{{1.2.12}{14}{Preimage, Inverse Image}{subsection.1.2.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.13}Convex Sets}{15}{subsection.1.2.13}}
\newlabel{eq:convexsets}{{1.11}{15}{Convex Sets}{equation.1.2.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.13.1}Example: Discrete Probability Distributions}{15}{subsubsection.1.2.13.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.14}Choice Sets, Transversal Sets, Cross-Sections}{15}{subsection.1.2.14}}
\newlabel{sec:choicesets}{{1.2.14}{15}{Choice Sets, Transversal Sets, Cross-Sections}{subsection.1.2.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.14.1}Example: Integers}{15}{subsubsection.1.2.14.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Set Operations}{15}{section.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}$A^c$ Complement}{15}{subsection.1.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}$\DOTSB \bigcup@ \slimits@ $ Union}{15}{subsection.1.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}$\DOTSB \bigcap@ \slimits@ $ Intersection}{16}{subsection.1.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.4}$\DOTSB \bigsqcup@ \slimits@ $ Disjoint Union, Discriminated Union}{16}{subsection.1.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Bijection Principle}{16}{section.1.4}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}DeMorgan's Rules}{16}{section.1.5}}
\newlabel{sec:demorgan}{{1.5}{16}{DeMorgan's Rules}{section.1.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Inclusion - Exclusion Principle}{16}{section.1.6}}
\newlabel{sec:inclusionexclusion}{{1.6}{16}{Inclusion - Exclusion Principle}{section.1.6}{}}
\citation{stanfordaxiomofchoice}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.1}Example: n=2 Sets and n=3 Sets}{17}{subsection.1.6.1}}
\@writefile{toc}{\contentsline {subparagraph}{n=2}{17}{subparagraph*.2}}
\@writefile{toc}{\contentsline {subparagraph}{n=3}{17}{subparagraph*.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.1.1}Example: Counting Integers}{17}{subsubsection.1.6.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Axiom of Choice}{17}{section.1.7}}
\newlabel{sec:axiomofchoice}{{1.7}{17}{Axiom of Choice}{section.1.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.1}Example: Pairs of Real Numbers, Right Inverse}{18}{subsection.1.7.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.8}$\sigma $-Algebras, $\sigma $-Fields}{18}{section.1.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.1}Definition}{18}{subsection.1.8.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.8.1.1}Example: The Smallest Possible $\sigma $-Algebra}{18}{subsubsection.1.8.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.8.1.2}Example: The Largest Possible $\sigma $-Algebra}{18}{subsubsection.1.8.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.2}Intersection Property}{18}{subsection.1.8.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.3}Generated $\sigma $-Algebras}{19}{subsection.1.8.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.8.3.1}Example: Generated $\sigma $-Algebra}{19}{subsubsection.1.8.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.4}Borel $\sigma $-Algebras ($\mathscr  {B}$) }{19}{subsection.1.8.4}}
\@writefile{toc}{\contentsline {section}{\numberline {1.9}Measures, Measurable Spaces and Measure Spaces}{19}{section.1.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.1}Example: Counting Measure}{19}{subsection.1.9.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.2}Example: Dirac Measure}{19}{subsection.1.9.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.3}Example: Volume Measure}{20}{subsection.1.9.3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.10}Measure Problem on $\mathbb  {R}$}{20}{section.1.10}}
\@writefile{toc}{\contentsline {paragraph}{}{20}{paragraph*.4}}
\@writefile{toc}{\contentsline {paragraph}{Claim}{20}{paragraph*.5}}
\@writefile{toc}{\contentsline {paragraph}{Proof}{20}{paragraph*.6}}
\@writefile{toc}{\contentsline {paragraph}{Claim}{20}{paragraph*.7}}
\@writefile{toc}{\contentsline {paragraph}{Proof}{20}{paragraph*.8}}
\@writefile{toc}{\contentsline {paragraph}{Claim}{20}{paragraph*.9}}
\@writefile{toc}{\contentsline {paragraph}{Proof}{20}{paragraph*.10}}
\@writefile{toc}{\contentsline {paragraph}{Assume}{21}{paragraph*.11}}
\@writefile{toc}{\contentsline {paragraph}{Conclusion}{21}{paragraph*.12}}
\@writefile{toc}{\contentsline {section}{\numberline {1.11}Measurable Maps}{21}{section.1.11}}
\@writefile{toc}{\contentsline {paragraph}{Definition}{21}{paragraph*.13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.11.1}Example: Characteristic Function, Indicator Function}{21}{subsection.1.11.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.11.2}Example: Composition of Measurable Maps}{21}{subsection.1.11.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.11.3}Example: Sums and Products of Measurable Maps}{21}{subsection.1.11.3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.12}Lebesgue Integrals}{22}{section.1.12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.12.1}Lebesgue Integrals for Step Functions}{22}{subsection.1.12.1}}
\@writefile{toc}{\contentsline {paragraph}{Characteristic Function}{22}{paragraph*.14}}
\@writefile{toc}{\contentsline {paragraph}{Simple Functions}{22}{paragraph*.15}}
\@writefile{toc}{\contentsline {paragraph}{S+}{22}{paragraph*.16}}
\@writefile{toc}{\contentsline {paragraph}{Lebesgue Integral for Simple Functions}{22}{paragraph*.17}}
\@writefile{toc}{\contentsline {paragraph}{Definition}{22}{paragraph*.18}}
\@writefile{toc}{\contentsline {section}{\numberline {1.13}Monotone Convergence Theorem}{23}{section.1.13}}
\@writefile{toc}{\contentsline {paragraph}{Preliminaries}{23}{paragraph*.19}}
\@writefile{toc}{\contentsline {subparagraph}{Equality}{23}{subparagraph*.20}}
\@writefile{toc}{\contentsline {subparagraph}{Monotonicity}{23}{subparagraph*.21}}
\@writefile{toc}{\contentsline {subparagraph}{Zero Integral}{23}{subparagraph*.22}}
\@writefile{toc}{\contentsline {paragraph}{Definition: Monotone Convergence Theorem}{24}{paragraph*.23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.13.1}Application: Series}{24}{subsection.1.13.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.14}Fatou's Lemma}{24}{section.1.14}}
\@writefile{toc}{\contentsline {section}{\numberline {1.15}Lebesgue's Dominated Convergence Theorem}{24}{section.1.15}}
\@writefile{toc}{\contentsline {paragraph}{Theorem}{25}{paragraph*.24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.15.1}Triangle Inequalities}{25}{subsection.1.15.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.16}Carath\'eodory's Extension Theorem}{25}{section.1.16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.16.1}Semirings of Sets}{25}{subsection.1.16.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.16.1.1}Example: Intervals on $\mathbb  {R}$}{25}{subsubsection.1.16.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.16.2}Pre-measure}{25}{subsection.1.16.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.16.3}Lebesgue Measure}{26}{subsection.1.16.3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.17}Lebesgue-Stieltjes Measures}{26}{section.1.17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.17.1}Example: Lebesgue Measure}{26}{subsection.1.17.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.17.2}Example: Zero Measure}{26}{subsection.1.17.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.17.3}Example: Dirac Measure}{26}{subsection.1.17.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.17.4}Example: Density Functions}{26}{subsection.1.17.4}}
\citation{kronenburg2011binomial}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Combinatorics}{27}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@2}}
\ttl@writefile{ptc}{\ttl@starttoc{default@3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Combinatorial Identities and Expansions}{27}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Binomial Coefficients and Binomial Expansions}{27}{subsection.2.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.1}Derivation of the Binomial Theorem for a Negative Exponent}{28}{subsubsection.2.1.1.1}}
\newlabel{eq:taylor}{{2.6}{28}{Derivation of the Binomial Theorem for a Negative Exponent}{equation.2.1.6}{}}
\newlabel{eq:derivatives}{{2.7}{28}{Derivation of the Binomial Theorem for a Negative Exponent}{equation.2.1.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.2}Derivation of the Binomial Theorem for a Fractional Exponent}{28}{subsubsection.2.1.1.2}}
\newlabel{eq:derivatives2}{{2.9}{28}{Derivation of the Binomial Theorem for a Fractional Exponent}{equation.2.1.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Multinomial Expansion}{29}{subsection.2.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Unnamed Polynomial Identity}{29}{subsection.2.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Factorial Expansion}{29}{subsection.2.1.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.5}Stirling Numbers of the Second Kind}{29}{subsection.2.1.5}}
\newlabel{sec:stirling2}{{2.1.5}{29}{Stirling Numbers of the Second Kind}{subsection.2.1.5}{}}
\citation{bogart2004combinatorics}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Distributions: The Twentyfold Way}{30}{section.2.2}}
\newlabel{twentyfoldway}{{2.2}{30}{Distributions: The Twentyfold Way}{section.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Bogart's Twentyfold Way}}{31}{figure.2.1}}
\@writefile{toc}{\contentsline {subparagraph}{Favorite Teachers}{31}{subparagraph*.25}}
\@writefile{toc}{\contentsline {subparagraph}{Assembling a Team}{31}{subparagraph*.26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Distinct Objects}{31}{subsection.2.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1.1}Distinct Recipients}{31}{subsubsection.2.2.1.1}}
\@writefile{toc}{\contentsline {subparagraph}{Pool Balls into Labeled Buckets}{31}{subparagraph*.27}}
\@writefile{toc}{\contentsline {subparagraph}{Functions}{31}{subparagraph*.28}}
\@writefile{toc}{\contentsline {subparagraph}{Binary Strings of Length $k$}{32}{subparagraph*.29}}
\@writefile{toc}{\contentsline {subparagraph}{Subsets of a $k$-Element Set}{32}{subparagraph*.30}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1.2}Indistinct Recipients}{32}{subsubsection.2.2.1.2}}
\newlabel{eq:stirling2}{{2.25}{32}{Indistinct Recipients}{equation.2.2.25}{}}
\@writefile{toc}{\contentsline {subparagraph}{Pool Balls into Unlabeled Bags}{32}{subparagraph*.31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Distinct Objects, Every Recipient Receives At Most One}{32}{subsection.2.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2.1}Distinct Recipients}{32}{subsubsection.2.2.2.1}}
\@writefile{toc}{\contentsline {subparagraph}{At Most One Pool Ball into Labeled Buckets}{32}{subparagraph*.32}}
\@writefile{toc}{\contentsline {subparagraph}{One-to-One Functions}{32}{subparagraph*.33}}
\@writefile{toc}{\contentsline {subparagraph}{k-element Permutations of $n$ elements}{32}{subparagraph*.34}}
\@writefile{toc}{\contentsline {subparagraph}{Books on a Shelf}{32}{subparagraph*.35}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2.2}Indistinct Recipients}{33}{subsubsection.2.2.2.2}}
\@writefile{toc}{\contentsline {subparagraph}{At Most One Pool Ball into Unlabeled Bags}{33}{subparagraph*.36}}
\@writefile{toc}{\contentsline {subparagraph}{Distributing Candy}{33}{subparagraph*.37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Distinct Objects, Every Recipient Receives at Least One}{33}{subsection.2.2.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.1}Distinct Recipients}{33}{subsubsection.2.2.3.1}}
\@writefile{toc}{\contentsline {subparagraph}{At Least One Pool Ball into Labeled Buckets}{33}{subparagraph*.38}}
\@writefile{toc}{\contentsline {subparagraph}{Onto Functions}{33}{subparagraph*.39}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.2}Indistinct Recipients}{33}{subsubsection.2.2.3.2}}
\@writefile{toc}{\contentsline {subparagraph}{At Least One Pool Ball into Unlabeled Bags}{33}{subparagraph*.40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Distinct Objects, Every Recipient Receives Exactly One}{34}{subsection.2.2.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.1}Distinct Recipients}{34}{subsubsection.2.2.4.1}}
\@writefile{toc}{\contentsline {subparagraph}{Exactly One Pool Ball into Each Labeled Buckets}{34}{subparagraph*.41}}
\@writefile{toc}{\contentsline {subparagraph}{Bijective Functions}{34}{subparagraph*.42}}
\@writefile{toc}{\contentsline {subparagraph}{Permutations}{34}{subparagraph*.43}}
\@writefile{toc}{\contentsline {subparagraph}{Unique Identifiers}{34}{subparagraph*.44}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4.2}Indistinct Recipients}{34}{subsubsection.2.2.4.2}}
\@writefile{toc}{\contentsline {subparagraph}{Exactly One Pool Ball into Each Unlabeled Bag}{34}{subparagraph*.45}}
\@writefile{toc}{\contentsline {subparagraph}{Distribute without Leftovers}{34}{subparagraph*.46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Distinct Objects, Distributed in Ordered Groups}{34}{subsection.2.2.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5.1}Distinct Recipients}{34}{subsubsection.2.2.5.1}}
\@writefile{toc}{\contentsline {subparagraph}{Books on Labeled Bookshelves}{35}{subparagraph*.47}}
\@writefile{toc}{\contentsline {subparagraph}{Ordered Functions}{35}{subparagraph*.48}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5.2}Indistinct Recipients}{35}{subsubsection.2.2.5.2}}
\@writefile{toc}{\contentsline {subparagraph}{Books into Unlabeled Boxes}{35}{subparagraph*.49}}
\@writefile{toc}{\contentsline {subparagraph}{Broken Permutations $\leq n$ Parts}{35}{subparagraph*.50}}
\@writefile{toc}{\contentsline {subparagraph}{Books into Boxes}{35}{subparagraph*.51}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.6}Distinct Objects, Distributed in Ordered Groups of At Least One}{35}{subsection.2.2.6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.1}Distinct Recipients}{35}{subsubsection.2.2.6.1}}
\@writefile{toc}{\contentsline {subparagraph}{Books on Labeled Bookshelves}{36}{subparagraph*.52}}
\@writefile{toc}{\contentsline {subparagraph}{Ordered Onto Functions}{36}{subparagraph*.53}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6.2}Indistinct Recipients}{36}{subsubsection.2.2.6.2}}
\@writefile{toc}{\contentsline {subparagraph}{Books into Unlabeled Boxes}{36}{subparagraph*.54}}
\@writefile{toc}{\contentsline {subparagraph}{Broken Permutations $n$ parts}{36}{subparagraph*.55}}
\@writefile{toc}{\contentsline {subparagraph}{Books into Boxes}{36}{subparagraph*.56}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.7}Identical Objects}{36}{subsection.2.2.7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.7.1}Distinct Recipients}{36}{subsubsection.2.2.7.1}}
\@writefile{toc}{\contentsline {subparagraph}{Ping Pong Balls into Labeled Buckets}{36}{subparagraph*.57}}
\@writefile{toc}{\contentsline {subparagraph}{Multisets}{36}{subparagraph*.58}}
\@writefile{toc}{\contentsline {subparagraph}{Integer Sums}{36}{subparagraph*.59}}
\@writefile{toc}{\contentsline {subparagraph}{Bosons in Degenerate States}{37}{subparagraph*.60}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.7.2}Indistinct Recipients}{37}{subsubsection.2.2.7.2}}
\@writefile{toc}{\contentsline {subparagraph}{Ping Pong Balls into Unlabeled Bags}{37}{subparagraph*.61}}
\@writefile{toc}{\contentsline {subparagraph}{Number Partitions}{37}{subparagraph*.62}}
\@writefile{toc}{\contentsline {subparagraph}{Unlabeled Multiplicities of Multisets}{37}{subparagraph*.63}}
\@writefile{toc}{\contentsline {subparagraph}{Boxes of Marbles}{37}{subparagraph*.64}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.8}Identical Objects, Each Receives At Most One}{37}{subsection.2.2.8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.8.1}Distinct Recipients}{37}{subsubsection.2.2.8.1}}
\@writefile{toc}{\contentsline {subparagraph}{At Most One Ping Pong Balls into Labeled Buckets}{37}{subparagraph*.65}}
\@writefile{toc}{\contentsline {subparagraph}{Subsets}{37}{subparagraph*.66}}
\@writefile{toc}{\contentsline {subparagraph}{Set Binary Labels}{37}{subparagraph*.67}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.8.2}Indistinct Recipients}{37}{subsubsection.2.2.8.2}}
\@writefile{toc}{\contentsline {subparagraph}{At Most One Ping Pong Ball into Unlabeled Bags}{37}{subparagraph*.68}}
\@writefile{toc}{\contentsline {subparagraph}{Boxes}{38}{subparagraph*.69}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.9}Identical Objects, Each Receives At Least One}{38}{subsection.2.2.9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.9.1}Distinct Recipients}{38}{subsubsection.2.2.9.1}}
\@writefile{toc}{\contentsline {subparagraph}{At Least One Ping Pong Ball into Labeled Buckets}{38}{subparagraph*.70}}
\@writefile{toc}{\contentsline {subparagraph}{Compositions $n$ Parts}{38}{subparagraph*.71}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.9.2}Indistinct Recipients}{38}{subsubsection.2.2.9.2}}
\@writefile{toc}{\contentsline {subparagraph}{At Least One Ping Pong Ball in Unlabeled Bags}{38}{subparagraph*.72}}
\@writefile{toc}{\contentsline {subparagraph}{Partitions in $n$ Parts}{38}{subparagraph*.73}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.10}Identical Objects, Each Receives Exactly One}{38}{subsection.2.2.10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.10.1}Distinct Recipients}{38}{subsubsection.2.2.10.1}}
\@writefile{toc}{\contentsline {subparagraph}{One Ping Pong Ball into Each Labeled Bucket}{38}{subparagraph*.74}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.10.2}Indistinct Recipients}{38}{subsubsection.2.2.10.2}}
\@writefile{toc}{\contentsline {subparagraph}{One Ping Pong Ball into Each Unlabeled Bag}{38}{subparagraph*.75}}
\citation{bogart2004combinatorics}
\citation{wilf2013generating}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Generating Functions}{39}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Example: Binomial Coefficients}{39}{subsection.2.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Example: Basket of Goods}{39}{subsection.2.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Example: Dice}{40}{subsection.2.3.3}}
\newlabel{eq:d6}{{2.57}{40}{Example: Dice}{equation.2.3.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Probability of the sum of 6-sided and 20-sided dice, calculated with Eqn. \ref  {eq:d6}. Note that these are simply the convolutions of $n=1,2,3,...$ square waves, which rapidly adopts the shape of a Bell curve.}}{41}{figure.2.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Linear Algebra and Multivariable Calculus}{43}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@3}}
\ttl@writefile{ptc}{\ttl@starttoc{default@4}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Multi-Index Notation}{43}{section.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Example: Multinomial Coefficients}{44}{subsection.3.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Example: Taylor Expansion}{44}{subsection.3.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Matrix Multiplication}{44}{section.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.0.1}Elementwise}{44}{subsubsection.3.2.0.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.0.2}Columns of $\mathbf  {C}$}{45}{subsubsection.3.2.0.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.0.3}Rows of $\mathbf  {C}$}{45}{subsubsection.3.2.0.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Linear Systems of Equations}{45}{section.3.3}}
\newlabel{sec:linearequations}{{3.3}{45}{Linear Systems of Equations}{section.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}$A\in \mathbb  {R}^{n\times n}$ Square Matrices}{45}{subsection.3.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}$A\in \mathbb  {R}^{m\times n}$ Rectangular Matrices, Overdetermined Case}{46}{subsection.3.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}$A\in \mathbb  {R}^{n\times m}$ Rectangular Matrices, Underdetermined Case}{46}{subsection.3.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}$\mathbf  {A} = \mathbf  {L}\mathbf  {L}^{\dagger }$ Cholesky Decomposition}{46}{section.3.4}}
\newlabel{sec:cholesky}{{3.4}{46}{$\mathbf {A} = \mathbf {L}\mathbf {L}^{\dagger }$ Cholesky Decomposition}{section.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Creating Correlated Random Variables}{46}{subsection.3.4.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Generalized Eigenvectors}{46}{section.3.5}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}$\mathbf  {A} = \mathbf  {V\Lambda V^{-1}}$ Spectral Theorems, Diagonalization}{46}{section.3.6}}
\newlabel{sec:diagonalization}{{3.6}{46}{$\mathbf {A} = \mathbf {V\Lambda V^{-1}}$ Spectral Theorems, Diagonalization}{section.3.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Creating correlated random variables from uncorrelated random variables using the Cholesky decomposition of the covariance matrix. The 5 uncorrelated random variables are sampled from a standard normal distribution. It is difficult to see a difference between the correlated and uncorrelated random walks.}}{47}{figure.3.1}}
\citation{mathworkseig}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}$\mathbf  {A} = \mathbf  {V\Lambda V}^T$ Eigendecomposition of Symmetric Matrices}{48}{subsection.3.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}$\mathbf  {H} = \mathbf  {U\Lambda U}^T$ Eigendecomposition of Hermitian Matrices}{48}{subsection.3.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.3}Eigenvalue Sensitivity and Accuracy}{48}{subsection.3.6.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.3.1}General Case}{48}{subsubsection.3.6.3.1}}
\citation{friedman2001elements}
\citation{friedman2001elements}
\citation{friedman2001elements}
\citation{mathworkseigs}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.3.2}Hermitian Matrices}{49}{subsubsection.3.6.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}$\mathbf  {A} = \mathbf  {U\Sigma V}^{\dagger }$ Singular Value Decomposition}{49}{section.3.7}}
\newlabel{sec:svd}{{3.7}{49}{$\mathbf {A} = \mathbf {U\Sigma V}^{\dagger }$ Singular Value Decomposition}{section.3.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.1}Full and Economy SVDs}{49}{subsection.3.7.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.2}Matrix Approximation}{49}{subsection.3.7.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Dimensions for Full vs. Economy SVDs}}{50}{figure.3.2}}
\newlabel{fig:full_vs_economy_svd}{{3.2}{50}{Dimensions for Full vs. Economy SVDs}{figure.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.3}Geometric Interpretation of SVD}{50}{subsection.3.7.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.8}Schur Decomposition}{51}{section.3.8}}
\@writefile{toc}{\contentsline {section}{\numberline {3.9}Types of Transformations}{51}{section.3.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.1}Similarity Transformations}{51}{subsection.3.9.1}}
\newlabel{sec:similaritytrans}{{3.9.1}{51}{Similarity Transformations}{subsection.3.9.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.2}Affine Transformations}{51}{subsection.3.9.2}}
\newlabel{sec:affine}{{3.9.2}{51}{Affine Transformations}{subsection.3.9.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.3}Unitary Transformations}{51}{subsection.3.9.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.4}Multilinear Maps}{52}{subsection.3.9.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.5}Multilinear Forms}{52}{subsection.3.9.5}}
\@writefile{toc}{\contentsline {section}{\numberline {3.10}Types of Matrices, Matrix Properties}{52}{section.3.10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.1}$\mathrm  {sgn}\left (\mathbf  {x}^{\dagger }\mathbf  {H}\mathbf  {x}\right )$ Definite}{52}{subsection.3.10.1}}
\newlabel{sec:definite}{{3.10.1}{52}{$\mathrm {sgn}\left (\mathbf {x}^{\dagger }\mathbf {H}\mathbf {x}\right )$ Definite}{subsection.3.10.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.2}Triangular}{52}{subsection.3.10.2}}
\newlabel{sec:triangular}{{3.10.2}{52}{Triangular}{subsection.3.10.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.3}$\mathbf  {AB}-\mathbf  {BA}=0$ Commuting}{52}{subsection.3.10.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.4}$\mathbf  {AB}+\mathbf  {BA}=0$ Anticommuting}{53}{subsection.3.10.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.5}$\mathbf  {A}^{\dagger } = \mathbf  {A}$ Hermitian, Symmetric}{53}{subsection.3.10.5}}
\newlabel{sec:hermitian}{{3.10.5}{53}{$\mathbf {A}^{\dagger } = \mathbf {A}$ Hermitian, Symmetric}{subsection.3.10.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.10.5.1}Properties}{53}{subsubsection.3.10.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.6}$\mathbf  {A}^{\dagger } = -\mathbf  {A}$ Skew Hermitian, Skew Symmetric}{53}{subsection.3.10.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.7}$\mathbf  {A}\mathbf  {A}=\mathbf  {I}$ Involutory}{53}{subsection.3.10.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.8}$||\mathbf  {A}\mathbf  {x}||_{\alpha } = ||\mathbf  {x}||_{\alpha }$ Isometric}{54}{subsection.3.10.8}}
\newlabel{sec:isometric}{{3.10.8}{54}{$||\mathbf {A}\mathbf {x}||_{\alpha } = ||\mathbf {x}||_{\alpha }$ Isometric}{subsection.3.10.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.10.8.1}Isometries with Respect to $L^2$}{54}{subsubsection.3.10.8.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.10.8.2}Isometries with Respect to $L^1$ and general $L^q\not =L^2$}{54}{subsubsection.3.10.8.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.9}Stochastic}{54}{subsection.3.10.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.10}$\mathbf  {U}^{\dagger } = \mathbf  {U}^{-1}$ Unitary, Orthogonal}{55}{subsection.3.10.10}}
\newlabel{sec:unitary}{{3.10.10}{55}{$\mathbf {U}^{\dagger } = \mathbf {U}^{-1}$ Unitary, Orthogonal}{subsection.3.10.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.11}$\mathbf  {A} = \mathbf  {TBT^{-1}}$ Similarity}{55}{subsection.3.10.11}}
\newlabel{sec:similiarity}{{3.10.11}{55}{$\mathbf {A} = \mathbf {TBT^{-1}}$ Similarity}{subsection.3.10.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.11}Properties of Norms}{55}{section.3.11}}
\@writefile{toc}{\contentsline {section}{\numberline {3.12}$L^p$ Lebesgue Vector Norms}{55}{section.3.12}}
\newlabel{sec:lpnorms}{{3.12}{55}{$L^p$ Lebesgue Vector Norms}{section.3.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.12.1}$L^{1}$ Taxicab / Manhattan Norm}{55}{subsection.3.12.1}}
\newlabel{sec:l1norm}{{3.12.1}{55}{$L^{1}$ Taxicab / Manhattan Norm}{subsection.3.12.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.12.2}$L^{2}$ Euclidian Norm}{55}{subsection.3.12.2}}
\newlabel{sec:l2norm}{{3.12.2}{55}{$L^{2}$ Euclidian Norm}{subsection.3.12.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Unit Circles: Level sets $\{\mathbf  {x}: ||\mathbf  {x}||_q = 1\}$ for different $L^q$ norms.}}{56}{figure.3.3}}
\newlabel{fig:unitsets}{{3.3}{56}{Unit Circles: Level sets $\{\mathbf {x}: ||\mathbf {x}||_q = 1\}$ for different $L^q$ norms}{figure.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Distance metrics base for different $L^q$ norms.}}{56}{figure.3.4}}
\newlabel{fig:unitsets}{{3.4}{56}{Distance metrics base for different $L^q$ norms}{figure.3.4}{}}
\citation{rgeraNotes}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.12.3}$L^{\infty }$ Maximum Norm}{57}{subsection.3.12.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.12.4}$L^{-\infty }$ Minimum Norm}{57}{subsection.3.12.4}}
\@writefile{toc}{\contentsline {section}{\numberline {3.13}Operator and Matrix Norms}{57}{section.3.13}}
\newlabel{sec:norms}{{3.13}{57}{Operator and Matrix Norms}{section.3.13}{}}
\@writefile{toc}{\contentsline {subparagraph}{}{57}{subparagraph*.76}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.13.1}$||\mathbf  {A}||_{(\alpha )}$ Operator Norm}{57}{subsection.3.13.1}}
\newlabel{sec:operatornorm}{{3.13.1}{57}{$||\mathbf {A}||_{(\alpha )}$ Operator Norm}{subsection.3.13.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.13.2}$||\mathbf  {A}||_q$ $q$-Norms}{58}{subsection.3.13.2}}
\newlabel{sec:qnorms}{{3.13.2}{58}{$||\mathbf {A}||_q$ $q$-Norms}{subsection.3.13.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.13.3}$||\mathbf  {A}||_F$ Frobenius Norm}{58}{subsection.3.13.3}}
\newlabel{sec:frobenius}{{3.13.3}{58}{$||\mathbf {A}||_F$ Frobenius Norm}{subsection.3.13.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.13.4}$||\mathbf  {A}||_{(1)}$ (1)-Norm}{58}{subsection.3.13.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.13.5}$||\mathbf  {A}||_{(\infty )}$ ($\infty $)-Norm}{58}{subsection.3.13.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.13.6}$||\mathbf  {A}||_{(2)}$ (2)-Norm}{58}{subsection.3.13.6}}
\newlabel{sec:2norm}{{3.13.6}{58}{$||\mathbf {A}||_{(2)}$ (2)-Norm}{subsection.3.13.6}{}}
\citation{barnesmatrixdiff}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.13.7}$||\mathbf  {A}||_{*}$ Nuclear Norm}{59}{subsection.3.13.7}}
\newlabel{sec:nuclearnorm}{{3.13.7}{59}{$||\mathbf {A}||_{*}$ Nuclear Norm}{subsection.3.13.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.14}Vector and Matrix Derivatives}{59}{section.3.14}}
\newlabel{sec:derivatives}{{3.14}{59}{Vector and Matrix Derivatives}{section.3.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.14.1}Jacobian}{59}{subsection.3.14.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.14.2}Inverse Function Theorem}{59}{subsection.3.14.2}}
\newlabel{sec:inverse_function_theorem}{{3.14.2}{59}{Inverse Function Theorem}{subsection.3.14.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.14.3}Critical Points}{60}{subsection.3.14.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.14.4}Differential Volume Element, Change of Variables}{60}{subsection.3.14.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.14.5}Hessian}{60}{subsection.3.14.5}}
\newlabel{sec:hessian}{{3.14.5}{60}{Hessian}{subsection.3.14.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.14.5.1}Testing Convexity}{61}{subsubsection.3.14.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.15}Fundamental Theorems of Calculus}{61}{section.3.15}}
\@writefile{toc}{\contentsline {section}{\numberline {3.16}Leibnitz Integral Rule}{61}{section.3.16}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Probability}{63}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@4}}
\ttl@writefile{ptc}{\ttl@starttoc{default@5}}
\citation{wasserman2013all}
\citation{lindgren2006lectures}
\citation{brightsideofmathematics}
\citation{blitzstein2019introduction}
\citation{wasserman2013all}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Interpretations and Definitions of Probability}{64}{section.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Blitzstein's Naive and Non-Naive Definitions of Probability}{64}{subsection.4.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1.1}Naive Probability, Uniform Probability}{64}{subsubsection.4.1.1.1}}
\citation{blitzstein2019introduction}
\citation{wasserman2013all}
\citation{wasserman2013all}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1.2}Blitzstein's Non-Naive Definition of Probability}{65}{subsubsection.4.1.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Frequentist Probability}{65}{subsection.4.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Bayesian Probability}{65}{subsection.4.1.3}}
\@writefile{toc}{\contentsline {paragraph}{}{65}{paragraph*.77}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}Kolmogorov's Axioms}{66}{subsection.4.1.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.5}Cox' Theorems}{66}{subsection.4.1.5}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Measure Theoretic Probability}{66}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Sample Space, Outcomes, Events}{66}{subsection.4.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Probability Distributions}{66}{subsection.4.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Random Variables}{67}{subsection.4.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Cumulative Distribution Function (CDF)}{67}{subsection.4.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.5}Probability Mass Function (PMF)}{67}{subsection.4.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.6}Probability Density Function (PDF)}{67}{subsection.4.2.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.7}Quantile Function (Inverse CDF)}{67}{subsection.4.2.7}}
\citation{wasserman2013all}
\citation{wasserman2013all}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.8}Joint, Conditional and Marginal Distributions}{68}{subsection.4.2.8}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Mutually Exclusive Events, Disjoint Sets}{68}{section.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Independent Events}{68}{section.4.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Conditional Probability}{68}{section.4.5}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Law of Total Probability}{68}{section.4.6}}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Bayes' Theorem}{68}{section.4.7}}
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Functions of Random Variables, Derived Distributions}{69}{section.4.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.1}Example: Sum of Random Variables}{70}{subsection.4.8.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.2}Example: Lower Dimensional Random Variable}{70}{subsection.4.8.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.9}Indicator Variables}{70}{section.4.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.1}Example: The Party Problem}{71}{subsection.4.9.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.9.1.1}Lame Interview Question 1: Every one finds their coat}{71}{subsubsection.4.9.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.9.1.2}Lame Interview Question 2: At least r people find their coat}{71}{subsubsection.4.9.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.9.1.3}Not lame: Exactly r people find their coat}{72}{subsubsection.4.9.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Simulated and analytically calculated probabilities that exactly $r$ people at a $n=100$ people party randomly pick up their coat.}}{74}{figure.4.1}}
\newlabel{fig:proba_partyproblem}{{4.1}{74}{Simulated and analytically calculated probabilities that exactly $r$ people at a $n=100$ people party randomly pick up their coat}{figure.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.10}Copulas}{74}{section.4.10}}
\@writefile{toc}{\contentsline {section}{\numberline {4.11}Relationships Between Distributions}{74}{section.4.11}}
\@writefile{toc}{\contentsline {section}{\numberline {4.12}Large Deviation Theory}{74}{section.4.12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12.1}Gaertner-Ellis Theorem}{74}{subsection.4.12.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.12.2}Example: Sum of Uniform Random Variables}{74}{subsection.4.12.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.13}Point Mass Distributions}{74}{section.4.13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.13.1}Kronecker Delta $\delta _{\alpha }$}{74}{subsection.4.13.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.13.2}Dirac Delta Function $\delta (x-\alpha )$}{74}{subsection.4.13.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.14}Uniform Distributions}{75}{section.4.14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.14.1}Discrete Uniform $\mathrm  {Uniform(1,k)}$}{75}{subsection.4.14.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.14.2}Continuous Uniform $\mathrm  {Uniform(a,b)}$}{75}{subsection.4.14.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.15}Bernoulli Processes}{75}{section.4.15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.15.1}Bernoulli $\mathrm  {Bernoulli(p)}$}{75}{subsection.4.15.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.15.2}Binomial $\mathrm  {Binomial}(n,p)$}{75}{subsection.4.15.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.15.3}Geometric $\mathrm  {Geom}(p)$}{76}{subsection.4.15.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.15.4}Pascal, Negative Binomial $\mathrm  {NB}(r,p)$}{76}{subsection.4.15.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4.16}Bernoulli Processes Without Replacement}{76}{section.4.16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.16.1}Hypergeometric $\mathrm  {Hypergeom(N,K,n)}$}{76}{subsection.4.16.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.16.2}Negative Hypergeometric $\mathrm  {NH(N,K,n)}$}{76}{subsection.4.16.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.17}Poisson Point Processes}{77}{section.4.17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.17.1}Poisson $\mathrm  {Poisson}(\Lambda )$}{77}{subsection.4.17.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.17.2}Exponential $\mathrm  {Exp}(\lambda )$}{77}{subsection.4.17.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.17.3}Gamma $\mathrm  {Gamma(\alpha ,\beta )}$}{77}{subsection.4.17.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.18}$t$-Distribution $\mathrm  {t_\nu \ }$}{78}{section.4.18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.18.1}Cauchy Distribution $t_1$}{78}{subsection.4.18.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.19}Chi$^2$-Distribution $\chi ^2_p$}{78}{section.4.19}}
\@writefile{toc}{\contentsline {section}{\numberline {4.20}Normal $\mathscr  {N}(\mu ,\sigma ^2)$}{78}{section.4.20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.20.1}Standard Normal Distribution $\mathscr  {N}(0,1)$ }{78}{subsection.4.20.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.20.1.1}Example: Interval $\mathbb  {P}(a<X<b)$}{78}{subsubsection.4.20.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.20.1.2}Example: Quantile $x = F^{-1}(q)$}{78}{subsubsection.4.20.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.21}Log Normal Distribution}{78}{section.4.21}}
\@writefile{toc}{\contentsline {section}{\numberline {4.22}Categorial Processes, Multinoulli Processes}{78}{section.4.22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.22.1}Categorical, Multinoulli $\mathrm  {Categorical(\mathbf  {p})}$}{79}{subsection.4.22.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.22.2}Multinomial $\mathrm  {Multinomial(n,\mathbf  {p})}$}{79}{subsection.4.22.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.23}Beta $\mathrm  {Beta}(\alpha ,\beta )$}{79}{section.4.23}}
\@writefile{toc}{\contentsline {section}{\numberline {4.24}Dirichlet $\mathrm  {Dirichlet}(\mathbf  {\alpha })$}{79}{section.4.24}}
\@writefile{toc}{\contentsline {section}{\numberline {4.25}Multivariate Normal $\mathscr  {N}(\mathbf  {\mu },\mathbf  {\Sigma })$}{79}{section.4.25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.25.1}Covariance Matrix $\mathbf  {\Sigma }$}{80}{subsection.4.25.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.25.2}Marginal Distribution}{80}{subsection.4.25.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.25.3}Conditional Distribution}{80}{subsection.4.25.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.25.4}Vector Multiplication}{80}{subsection.4.25.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.25.5}Relationship to Chi$^2$}{80}{subsection.4.25.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.25.6}Multivariate Standard Normal Distribution $\mathscr  {N}(\mathbf  {0},\mathbf  {\Sigma })$}{80}{subsection.4.25.6}}
\@writefile{toc}{\contentsline {section}{\numberline {4.26}Expectations}{80}{section.4.26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.26.1}Law of the Unconscious Statistician}{80}{subsection.4.26.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.26.2}Linearity of Expeced Value}{81}{subsection.4.26.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.27}Moments, Central Moments}{81}{section.4.27}}
\@writefile{toc}{\contentsline {section}{\numberline {4.28}Variance}{81}{section.4.28}}
\@writefile{toc}{\contentsline {section}{\numberline {4.29}Mean and Variance of Vector Valued Random Variables}{81}{section.4.29}}
\@writefile{toc}{\contentsline {section}{\numberline {4.30}Covariance, Correlation}{81}{section.4.30}}
\@writefile{toc}{\contentsline {section}{\numberline {4.31}Sample Mean and Sample Variance}{82}{section.4.31}}
\@writefile{toc}{\contentsline {section}{\numberline {4.32}Law of Iterated Expectation}{82}{section.4.32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.32.1}Applied to Variance}{82}{subsection.4.32.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.33}Moment Generating Functions, Laplace Transforms}{82}{section.4.33}}
\@writefile{toc}{\contentsline {section}{\numberline {4.34}Cumulant Generating Functions}{82}{section.4.34}}
\@writefile{toc}{\contentsline {section}{\numberline {4.35}Characteristic Function}{83}{section.4.35}}
\@writefile{toc}{\contentsline {section}{\numberline {4.36}Inequalities for Probabilities}{83}{section.4.36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.36.1}Markov's Inequality}{83}{subsection.4.36.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.36.2}Chebyshev's Inequality}{83}{subsection.4.36.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.36.3}Hoeffding's Inequality}{83}{subsection.4.36.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.36.3.1}Example: Bernoulli Random Variables}{83}{subsubsection.4.36.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.36.4}Mill's Inequality}{83}{subsection.4.36.4}}
\citation{wasserman2013all}
\@writefile{toc}{\contentsline {section}{\numberline {4.37}Inequalities for Expectations}{84}{section.4.37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.37.1}Cauchy-Schwarz Inequality}{84}{subsection.4.37.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.37.2}Jensen's Inequality}{84}{subsection.4.37.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.38}Asymptotic Theory}{84}{section.4.38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.38.1}Preasymptotics}{84}{subsection.4.38.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.38.2}Convergence in Probability}{84}{subsection.4.38.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.38.3}Convergence in Distribution}{84}{subsection.4.38.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.38.4}Convergence in Quadratic Mean, Convergence in $L_2$}{85}{subsection.4.38.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.38.5}Almost Sure Convergence}{85}{subsection.4.38.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.38.6}$L_1$ Convergence}{85}{subsection.4.38.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.38.7}Weak Law of Large Numbers}{85}{subsection.4.38.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.38.8}Strong Law of Large Numbers}{85}{subsection.4.38.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.38.9}Central Limit Theorem}{85}{subsection.4.38.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.38.10}Multivariate Central Limit Theorem}{85}{subsection.4.38.10}}
\citation{wasserman2013all}
\citation{wasserman2013all}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.38.11}Proof of the Central Limit Theorem}{86}{subsection.4.38.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.38.12}Delta Method}{86}{subsection.4.38.12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.38.12.1}Multivariate Delta Method}{87}{subsubsection.4.38.12.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.39}Classes of Distributions}{87}{section.4.39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.39.1}Stable Distributions}{87}{subsection.4.39.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.39.2}Sub-exponential}{87}{subsection.4.39.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.39.3}Exponential}{87}{subsection.4.39.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.39.4}Elliptical}{87}{subsection.4.39.4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Information Theory}{89}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@5}}
\ttl@writefile{ptc}{\ttl@starttoc{default@6}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Entropy}{89}{section.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Mutual Information}{89}{section.5.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Kullback-Leibler Divergence}{89}{section.5.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Stochastic Processes and Time Series Analysis}{91}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@6}}
\ttl@writefile{ptc}{\ttl@starttoc{default@7}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Branching Processes}{91}{section.6.1}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Markov Chains}{91}{section.6.2}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Martingales}{91}{section.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Martingale Convergence Theorem}{92}{subsection.6.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Hidden Markov Models}{92}{section.6.4}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Ito Calculus}{92}{section.6.5}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Chaos Analysis}{92}{section.6.6}}
\@writefile{toc}{\contentsline {section}{\numberline {6.7}Noise}{92}{section.6.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.1}White Noise}{92}{subsection.6.7.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.2}Gaussian Noise}{92}{subsection.6.7.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.3}Brownian Noise}{92}{subsection.6.7.3}}
\@writefile{toc}{\contentsline {section}{\numberline {6.8}Empirical Processes}{92}{section.6.8}}
\@writefile{toc}{\contentsline {section}{\numberline {6.9}Mean Field Theory, Fluid Approximation, Deterministic Approximation}{92}{section.6.9}}
\@writefile{toc}{\contentsline {section}{\numberline {6.10}Backtesting}{92}{section.6.10}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Statistical Inference}{93}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@7}}
\ttl@writefile{ptc}{\ttl@starttoc{default@8}}
\newlabel{chp:statisticalinference}{{7}{93}{Statistical Inference}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Parametric and Nonparametric Models}{93}{section.7.1}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Fundamental Concepts in Inference}{94}{section.7.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}Point Estimators}{94}{subsection.7.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.2}Bias}{94}{subsection.7.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.3}Consistency}{94}{subsection.7.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.4}Sampling Distribution, Standard Error}{94}{subsection.7.2.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.4.1}Example: Bernoulli Distribution}{94}{subsubsection.7.2.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.5}Mean Squared Error}{94}{subsection.7.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.6}Asymptotically Normal Estimators}{94}{subsection.7.2.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.7}Confidence Sets}{95}{subsection.7.2.7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.7.1}Normal-Based Confidence Intervals}{95}{subsubsection.7.2.7.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.7.2}Pointwise and Uniform Asymptotic Confidence Intervals}{95}{subsubsection.7.2.7.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.8}Pivots, Pivotal Quantities}{95}{subsection.7.2.8}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Non-Parametric Estimation of the CDF and Statistical Functionals}{95}{section.7.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.1}Empirical Distribution Function}{95}{subsection.7.3.1}}
\citation{wasserman2013all}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.2}Confidence Measures for the Empirical CDF}{96}{subsection.7.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.3}Statistical Functionals}{96}{subsection.7.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.4}Plug-in Estimator}{96}{subsection.7.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.5}Linear Functionals}{96}{subsection.7.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.6}Plug-in Estimator for Linear Functionals}{96}{subsection.7.3.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.7}Examples: Mean, Variance, Sample Variance, Sample Correlation}{96}{subsection.7.3.7}}
\citation{wasserman2003all}
\@writefile{toc}{\contentsline {section}{\numberline {7.4}The Bootstrap}{97}{section.7.4}}
\@writefile{toc}{\contentsline {section}{\numberline {7.5}Jackknife}{97}{section.7.5}}
\@writefile{toc}{\contentsline {section}{\numberline {7.6}Parametric Inference}{97}{section.7.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.1}Method of Moments}{97}{subsection.7.6.1}}
\citation{damask2019consistently}
\citation{damask2019consistently}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.2}Maximum Likelihood Estimation}{98}{subsection.7.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.3}Parametric Confidence Intervals}{98}{subsection.7.6.3}}
\@writefile{toc}{\contentsline {section}{\numberline {7.7}Score Function, Fisher Information}{98}{section.7.7}}
\@writefile{toc}{\contentsline {section}{\numberline {7.8}Directional Statistics}{98}{section.7.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.8.1}Mean Direction}{98}{subsection.7.8.1}}
\citation{damask2019consistently}
\citation{ncssridgeregression}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.8.2}Dispersion}{99}{subsection.7.8.2}}
\@writefile{toc}{\contentsline {section}{\numberline {7.9}Features}{99}{section.7.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.9.1}Dense Features, Sparse Features}{99}{subsection.7.9.1}}
\@writefile{toc}{\contentsline {section}{\numberline {7.10}Multicollinearity}{99}{section.7.10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.10.0.1}Detection}{99}{subsubsection.7.10.0.1}}
\@writefile{toc}{\contentsline {subparagraph}{Scatter Plots}{99}{subparagraph*.78}}
\citation{ncssridgeregression}
\@writefile{toc}{\contentsline {subparagraph}{Variance Inflation Factors (VIF)}{100}{subparagraph*.79}}
\@writefile{toc}{\contentsline {subparagraph}{Eigenvalues of the Correlation Matrix}{100}{subparagraph*.80}}
\@writefile{toc}{\contentsline {subparagraph}{Regression Coefficients}{100}{subparagraph*.81}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.10.1}Sources}{100}{subsection.7.10.1}}
\@writefile{toc}{\contentsline {subparagraph}{Data Collection}{100}{subparagraph*.82}}
\@writefile{toc}{\contentsline {subparagraph}{Physical Constraints}{100}{subparagraph*.83}}
\@writefile{toc}{\contentsline {subparagraph}{Over-defined Model}{100}{subparagraph*.84}}
\@writefile{toc}{\contentsline {subparagraph}{Model Choice or Specification}{100}{subparagraph*.85}}
\@writefile{toc}{\contentsline {subparagraph}{Outliers}{100}{subparagraph*.86}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.10.1.1}Remedies}{100}{subsubsection.7.10.1.1}}
\@writefile{toc}{\contentsline {subparagraph}{Dimensionality Reduction}{100}{subparagraph*.87}}
\@writefile{toc}{\contentsline {subparagraph}{Regularization}{100}{subparagraph*.88}}
\@writefile{toc}{\contentsline {section}{\numberline {7.11}Fat Tails}{100}{section.7.11}}
\@writefile{toc}{\contentsline {subparagraph}{Thin Tails}{100}{subparagraph*.89}}
\@writefile{toc}{\contentsline {subparagraph}{Fat Tails}{101}{subparagraph*.90}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.11.1}Consequences of Fat Tails}{101}{subsection.7.11.1}}
\@writefile{toc}{\contentsline {subparagraph}{The Law of Large Numbers works too Slowly}{101}{subparagraph*.91}}
\@writefile{toc}{\contentsline {subparagraph}{The Sample Mean will rarely correspond to the Distribution Mean}{101}{subparagraph*.92}}
\@writefile{toc}{\contentsline {subparagraph}{Metrics such as Sample Mean and Sample Variance will be Unusable}{101}{subparagraph*.93}}
\@writefile{toc}{\contentsline {subparagraph}{In finance, metrics like Sharp etc. are unusable}{101}{subparagraph*.94}}
\@writefile{toc}{\contentsline {subparagraph}{Gauss-Markov Theorem fails}{101}{subparagraph*.95}}
\@writefile{toc}{\contentsline {subparagraph}{Maximum Likelihood Methods can still work}{101}{subparagraph*.96}}
\@writefile{toc}{\contentsline {subparagraph}{Absence of Evidence $\not =$ Evidence of Absence}{101}{subparagraph*.97}}
\@writefile{toc}{\contentsline {subparagraph}{PCA is going to cause spurious factors and loads}{101}{subparagraph*.98}}
\@writefile{toc}{\contentsline {subparagraph}{Method of Moments does not work}{101}{subparagraph*.99}}
\@writefile{toc}{\contentsline {subparagraph}{There is no ``typical" large deviation}{101}{subparagraph*.100}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.11.2}Maximum to Sum}{101}{subsection.7.11.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.11.3}Maximum Domain of Attraction}{101}{subsection.7.11.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Probability densities of two independent thin tailed and thick tailed random variables (brazenly copied from Taleb, 2020). Compare to plot of Lp norms. For the thin tailed random variables, the observa- tion of a particular sum is most likely to result from a balanced contribution from both random variables. For the fat tailed random variables, the observation of a particular sum is most likely to result from the contribution of one of the variables.}}{102}{figure.7.1}}
\newlabel{fig:fattails01}{{7.1}{102}{Probability densities of two independent thin tailed and thick tailed random variables (brazenly copied from Taleb, 2020). Compare to plot of Lp norms. For the thin tailed random variables, the observa- tion of a particular sum is most likely to result from a balanced contribution from both random variables. For the fat tailed random variables, the observation of a particular sum is most likely to result from the contribution of one of the variables}{figure.7.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.11.4}Hidden Tail, Problems in Estimating Moments}{103}{subsection.7.11.4}}
\@writefile{toc}{\contentsline {section}{\numberline {7.12}$R^2$ Value}{103}{section.7.12}}
\@writefile{toc}{\contentsline {section}{\numberline {7.13}Regression Diagnostics}{103}{section.7.13}}
\@writefile{toc}{\contentsline {section}{\numberline {7.14}t-Statistics}{103}{section.7.14}}
\@writefile{toc}{\contentsline {section}{\numberline {7.15}AIC and BIC}{103}{section.7.15}}
\@writefile{toc}{\contentsline {section}{\numberline {7.16}Factor Regression}{103}{section.7.16}}
\@writefile{toc}{\contentsline {section}{\numberline {7.17}Factor Models}{103}{section.7.17}}
\@writefile{toc}{\contentsline {section}{\numberline {7.18}How to Combine Estimates with Different Uncertainties}{103}{section.7.18}}
\@writefile{toc}{\contentsline {section}{\numberline {7.19}How to Tackle Very High Dimensional Feature Spaces}{103}{section.7.19}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Linear Regression}{105}{chapter.8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@8}}
\ttl@writefile{ptc}{\ttl@starttoc{default@9}}
\newlabel{chap:linearregression}{{8}{105}{Linear Regression}{chapter.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Least Squares Regression ($L^2$)}{105}{section.8.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.1}The Normal Equations, Analytical Least Squares Estimator}{105}{subsection.8.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.2}The Quick Way to $\mathbf  {\mathaccentV {hat}05E{\beta }}$}{106}{subsection.8.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.3}The Long Way to $\mathbf  {\mathaccentV {hat}05E{\beta }}$}{106}{subsection.8.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.4}Projection Matrix}{106}{subsection.8.1.4}}
\citation{rodriguez2007generalized}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.5}Bayesian Perspective on Least Squares Regression}{107}{subsection.8.1.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.6}Q-plots}{107}{subsection.8.1.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.7}Variance Inflation Factor}{107}{subsection.8.1.7}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Total Least Squares}{107}{section.8.2}}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Ridge Regression (Tikhonov Regularization, $\lambda ||\mathbf  {\beta }||^2$)}{107}{section.8.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3.1}Analytical Ridge Estimator}{107}{subsection.8.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3.2}Bayesian Perspective on Ridge Regression}{107}{subsection.8.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {8.4}Least Absolute Shrinkage and Selection Operator Regression (LASSO)}{107}{section.8.4}}
\@writefile{toc}{\contentsline {section}{\numberline {8.5}Least Absolute Deviation Regression (LAD, $L^1$)}{107}{section.8.5}}
\@writefile{toc}{\contentsline {section}{\numberline {8.6}Generalized Linear Models}{107}{section.8.6}}
\@writefile{toc}{\contentsline {section}{\numberline {8.7}Count Regressions}{107}{section.8.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.7.1}Poisson Regression Models}{107}{subsection.8.7.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.7.1.1}Analogy to Least Squares Regression}{108}{subsubsection.8.7.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.7.1.2}Multivariate Poisson Model}{108}{subsubsection.8.7.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.7.1.3}Goodness of Fit}{108}{subsubsection.8.7.1.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.7.1.4}General$\mu = f(\mathbf  {x})$}{109}{subsubsection.8.7.1.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.7.1.5}Criticisms}{109}{subsubsection.8.7.1.5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Bayesian Data Analysis}{111}{chapter.9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@9}}
\ttl@writefile{ptc}{\ttl@starttoc{default@10}}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Markov Chain Monte Carlo Methods}{111}{section.9.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Unsupervised Learning}{113}{chapter.10}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@10}}
\ttl@writefile{ptc}{\ttl@starttoc{default@11}}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Blind Source Separation}{113}{section.10.1}}
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Clustering}{113}{section.10.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.1}K-Means}{113}{subsection.10.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2.2}Affinity Propagation}{113}{subsection.10.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Independent Component Analysis (ICA)}{113}{section.10.3}}
\@writefile{toc}{\contentsline {section}{\numberline {10.4}Compressed Sensing}{113}{section.10.4}}
\@writefile{toc}{\contentsline {section}{\numberline {10.5}$\mathbf  {X} = \mathbf  {U\Sigma V^T}$ Eigenanalysis, Singular Value Decomposition (SVD)}{113}{section.10.5}}
\newlabel{sec:datasvd}{{10.5}{113}{$\mathbf {X} = \mathbf {U\Sigma V^T}$ Eigenanalysis, Singular Value Decomposition (SVD)}{section.10.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.5.1}Example: Eigenfaces and Facial Recognition}{114}{subsection.10.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.5.2}Tracking an Eigensystem over Time}{114}{subsection.10.5.2}}
\newlabel{sec:svd_tracking}{{10.5.2}{114}{Tracking an Eigensystem over Time}{subsection.10.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.1}{\ignorespaces Left: The first 48 eigenfaces. The colorscale is consistent across the images. As can be expected, the eigenfaces seem to have an ordering from more general features, that are highly prevalent in the dataset, towards more specific features. Right: Five sample portraits from the dataset approximated using different numbers of eigenvectors. 2914 corresponds to the original image, which had 2914 pixels (degrees of freedom).}}{115}{figure.10.1}}
\newlabel{fig:svd_eigenfaces}{{10.1}{115}{Left: The first 48 eigenfaces. The colorscale is consistent across the images. As can be expected, the eigenfaces seem to have an ordering from more general features, that are highly prevalent in the dataset, towards more specific features. Right: Five sample portraits from the dataset approximated using different numbers of eigenvectors. 2914 corresponds to the original image, which had 2914 pixels (degrees of freedom)}{figure.10.1}{}}
\citation{damask2019consistently}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.5.2.1}Heuristic Method}{116}{subsubsection.10.5.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.5.2.2}Consistent Method}{116}{subsubsection.10.5.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.5.2.3}Rank Order Changes}{116}{subsubsection.10.5.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.5.3}Bayesian SVD}{116}{subsection.10.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.5.4}Randomized SVD}{116}{subsection.10.5.4}}
\newlabel{sec:rsvd}{{10.5.4}{116}{Randomized SVD}{subsection.10.5.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.5.4.1}Step 1: Sample Column Space of $\mathbf  {X}$ with $\mathbf  {P}$}{116}{subsubsection.10.5.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.2}{\ignorespaces Right singular vectors extracted using SVD, showing sign flips (top) and with a consistently oriented basis (bottom). The underlying data is a bivariate gaussian with principal axes undergoing a 180 degree rotation. With the consistently oriented basis, the singular vectors trace out a one-to-one trajectory that can be analyzed.}}{117}{figure.10.2}}
\newlabel{fig:svd_consistently_oriented}{{10.2}{117}{Right singular vectors extracted using SVD, showing sign flips (top) and with a consistently oriented basis (bottom). The underlying data is a bivariate gaussian with principal axes undergoing a 180 degree rotation. With the consistently oriented basis, the singular vectors trace out a one-to-one trajectory that can be analyzed}{figure.10.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.5.4.2}Step 2: Compute SVD on Projected $\mathbf  {Y = Q^T X}$}{118}{subsubsection.10.5.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {10.6}Principal Component Analysis (PCA)}{118}{section.10.6}}
\newlabel{sec:pca}{{10.6}{118}{Principal Component Analysis (PCA)}{section.10.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.3}{\ignorespaces Left: Time taken to perform conventional SVD (black line) and randomized SVD (colored lines) on the photo of the two young aristocrats which had a data matrix with rank $r=1277$. The different colors correspond to different numbers of power iterations performed ($q$). Right: Average mean square error (AMSE) of truncated SVD using matrices derived with randomized SVD compared with conventional SVD. Especially for small $r$, rSVD is significantly faster even after a few power iterations. For very small $r$, power iterations easily reduce the error introduced by the randomized method by several orders of magnitude, but at some point the method seems to increase the error. Perhaps this is due to numerical stability. I'm not sure. To somewhat account for random fluctuations, the curves shown are averaged over 20 trials.}}{119}{figure.10.3}}
\newlabel{fig:svd_scree}{{10.3}{119}{Left: Time taken to perform conventional SVD (black line) and randomized SVD (colored lines) on the photo of the two young aristocrats which had a data matrix with rank $r=1277$. The different colors correspond to different numbers of power iterations performed ($q$). Right: Average mean square error (AMSE) of truncated SVD using matrices derived with randomized SVD compared with conventional SVD. Especially for small $r$, rSVD is significantly faster even after a few power iterations. For very small $r$, power iterations easily reduce the error introduced by the randomized method by several orders of magnitude, but at some point the method seems to increase the error. Perhaps this is due to numerical stability. I'm not sure. To somewhat account for random fluctuations, the curves shown are averaged over 20 trials}{figure.10.3}{}}
\citation{amoeba2015svdpca}
\citation{brooks2012pcal1}
\citation{brooks2014pure}
\citation{brooks2014pure}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.6.1}Relationship between PCA and SVD}{120}{subsection.10.6.1}}
\newlabel{sec:pcasvd}{{10.6.1}{120}{Relationship between PCA and SVD}{subsection.10.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.6.2}Tracking Principal Components over Time}{120}{subsection.10.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.6.3}$L^1$-Norm Principal Component Analysis ($L^1$ PCA)}{120}{subsection.10.6.3}}
\newlabel{sec:l1pca}{{10.6.3}{120}{$L^1$-Norm Principal Component Analysis ($L^1$ PCA)}{subsection.10.6.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.7}$\mathbf  {X}=\mathbf  {W}\mathbf  {H}$ Non-Negative Matrix Factorization}{120}{section.10.7}}
\citation{gillis2014nonnegative}
\citation{morningpaper2019nnmf}
\citation{gillis2014nonnegative}
\@writefile{lof}{\contentsline {figure}{\numberline {10.4}{\ignorespaces Distance of a point to a hyperplane in $L^1$ and $L^2$. The $L^1$ distance in this case is just the distance along the $x$ axis. If the hyperplane was cutting a shallower angle, then the distance would be measured along the $y$ axis. The best fit hyperplane to many points in $\mathbb  {R}^2$ would be found by regressing the data points once with $y = \beta x + \epsilon $ and once with $x = \beta y + \epsilon $ and selecting the result with the smaller $||\epsilon ||_1$. (The figure is from J. P. Brooks (2014).}}{121}{figure.10.4}}
\newlabel{fig:l1pca}{{10.4}{121}{Distance of a point to a hyperplane in $L^1$ and $L^2$. The $L^1$ distance in this case is just the distance along the $x$ axis. If the hyperplane was cutting a shallower angle, then the distance would be measured along the $y$ axis. The best fit hyperplane to many points in $\mathbb {R}^2$ would be found by regressing the data points once with $y = \beta x + \epsilon $ and once with $x = \beta y + \epsilon $ and selecting the result with the smaller $||\epsilon ||_1$. (The figure is from J. P. Brooks (2014)}{figure.10.4}{}}
\citation{gavish2013optimal}
\citation{stevebrunton}
\@writefile{lof}{\contentsline {figure}{\numberline {10.5}{\ignorespaces Left: The first 34 basis faces stored in the $\mathbf  {W}$ matrix extracted using NNMF under Frobenius norm from the "Labeled Faces in the Wild" Dataset. The basis images are normalized and shown on a log scale because they have very different contrast and brightness. The normalized images are then all shown on the same color scale. Right: Five sample portraits from the dataset approximated using different numbers of basis faces. The NNMF was done for a value of $r=300$. The original portraits had $2914$ pixels. In contrast to SVD, the basis vectors obtained through NNMF do not necessarily have an internal ordering in terms of how much of the variance in the dataset they explain.}}{122}{figure.10.5}}
\newlabel{fig:nnmf_eigenfaces}{{10.5}{122}{Left: The first 34 basis faces stored in the $\mathbf {W}$ matrix extracted using NNMF under Frobenius norm from the "Labeled Faces in the Wild" Dataset. The basis images are normalized and shown on a log scale because they have very different contrast and brightness. The normalized images are then all shown on the same color scale. Right: Five sample portraits from the dataset approximated using different numbers of basis faces. The NNMF was done for a value of $r=300$. The original portraits had $2914$ pixels. In contrast to SVD, the basis vectors obtained through NNMF do not necessarily have an internal ordering in terms of how much of the variance in the dataset they explain}{figure.10.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.8}Optimal Truncation}{122}{section.10.8}}
\newlabel{sec:truncation}{{10.8}{122}{Optimal Truncation}{section.10.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.8.1}Scree Plots, Heuristic Methods}{122}{subsection.10.8.1}}
\newlabel{sec:scree}{{10.8.1}{122}{Scree Plots, Heuristic Methods}{subsection.10.8.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.6}{\ignorespaces Left: The first 6 basis faces stored in the $\mathbf  {W}$ matrix extracted using NNMF under Frobenius norm from the "Labeled Faces in the Wild" Dataset. Right: Sample images expressed in the reduced basis.}}{123}{figure.10.6}}
\newlabel{fig:nnmf_eigenfaces2}{{10.6}{123}{Left: The first 6 basis faces stored in the $\mathbf {W}$ matrix extracted using NNMF under Frobenius norm from the "Labeled Faces in the Wild" Dataset. Right: Sample images expressed in the reduced basis}{figure.10.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.7}{\ignorespaces Left: Original image of Princess Yvonne und Prince Alexander zu Sayn-Wittgenstein, photographed by their mother, Princess Marianne, in 1955 (1280 by 1277 pixels). Middle: Scree plot, which shows that the first few components are dominant in the image. Right: Cumulative plot that shows that the first singular component accounts for more than 20\% of the decomposition.}}{123}{figure.10.7}}
\newlabel{fig:svd_scree}{{10.7}{123}{Left: Original image of Princess Yvonne und Prince Alexander zu Sayn-Wittgenstein, photographed by their mother, Princess Marianne, in 1955 (1280 by 1277 pixels). Middle: Scree plot, which shows that the first few components are dominant in the image. Right: Cumulative plot that shows that the first singular component accounts for more than 20\% of the decomposition}{figure.10.7}{}}
\citation{gavish2013optimal}
\citation{gavish2013optimal}
\citation{gavish2013optimal}
\citation{hastie2015matrix}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.8.2}Gavish \& Donoho's Optimal Threshold for SVD}{124}{subsection.10.8.2}}
\@writefile{toc}{\contentsline {section}{\numberline {10.9}Matrix Completion, Imputation}{124}{section.10.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.9.1}Nuclear Norm Regularization}{124}{subsection.10.9.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.8}{\ignorespaces Left: Princess and Prince zu Sayn-Wittgenstein with different amounts of Gaussian noise added. Center: The same image estimated using TSVD with Gavish \& Donoho's approximate rank threshold. Right: Singular value spectrum of original, noise and truncated images. TSVD reduces the average mean square error (AMSE) with respect to the original image by over 50\%. Visually, the difference is not too perceptible.}}{125}{figure.10.8}}
\newlabel{fig:truncated_svd}{{10.8}{125}{Left: Princess and Prince zu Sayn-Wittgenstein with different amounts of Gaussian noise added. Center: The same image estimated using TSVD with Gavish \& Donoho's approximate rank threshold. Right: Singular value spectrum of original, noise and truncated images. TSVD reduces the average mean square error (AMSE) with respect to the original image by over 50\%. Visually, the difference is not too perceptible}{figure.10.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.9}{\ignorespaces Average means square error relative to the original image for the photo with added noise (blue) and after TSVD denoising (organge). The percentage of components retained via Gavish \& Donoho's approximate rank threshold shown in green. $\sigma _{\epsilon }$ is the standard deviation of the added (Gaussian) noise and $\sigma _0$ is the standard deviation of the pixel values of the original image. When $\sigma _{\epsilon }$ is small, G \& D automatically truncates the TSVD at about 40\% of the singular values, which is why, at first, the "denoised" image has greater error than the noisy issues.}}{126}{figure.10.9}}
\newlabel{fig:truncated_svd}{{10.9}{126}{Average means square error relative to the original image for the photo with added noise (blue) and after TSVD denoising (organge). The percentage of components retained via Gavish \& Donoho's approximate rank threshold shown in green. $\sigma _{\epsilon }$ is the standard deviation of the added (Gaussian) noise and $\sigma _0$ is the standard deviation of the pixel values of the original image. When $\sigma _{\epsilon }$ is small, G \& D automatically truncates the TSVD at about 40\% of the singular values, which is why, at first, the "denoised" image has greater error than the noisy issues}{figure.10.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.10}{\ignorespaces Results for different imputation methods reconstructing the image of the man rumored to be Bayes himself after 50\% of the pixels are removed.}}{127}{figure.10.10}}
\newlabel{fig:impute_05}{{10.10}{127}{Results for different imputation methods reconstructing the image of the man rumored to be Bayes himself after 50\% of the pixels are removed}{figure.10.10}{}}
\citation{mazumder2010spectral}
\newlabel{Autoencoders}{{10.9.1}{128}{Nuclear Norm Regularization}{equation.10.9.19}{}}
\newlabel{Variational Autoencoders}{{10.9.1}{128}{Nuclear Norm Regularization}{equation.10.9.19}{}}
\newlabel{Concept Vectors}{{10.9.1}{128}{Nuclear Norm Regularization}{equation.10.9.19}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Dynamical Systems}{129}{chapter.11}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@11}}
\ttl@writefile{ptc}{\ttl@starttoc{default@12}}
\newlabel{chp:dynamicalsystems}{{11}{129}{Dynamical Systems}{chapter.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}Mode Decompositions}{129}{section.11.1}}
\citation{cvitanovic2016chaos,salova2019koopman}
\citation{megretski2004pod}
\@writefile{toc}{\contentsline {section}{\numberline {11.2}Koopman and Frobenius-Perron Operators}{130}{section.11.2}}
\@writefile{toc}{\contentsline {section}{\numberline {11.3}Proper Orthogonal Decomposition (POD)}{130}{section.11.3}}
\citation{stevebrunton}
\citation{stevebrunton}
\@writefile{toc}{\contentsline {section}{\numberline {11.4}Dynamic Mode Decomposition (DMD)}{131}{section.11.4}}
\newlabel{sec:dmd}{{11.4}{131}{Dynamic Mode Decomposition (DMD)}{section.11.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.5}Extended Dynamical Mode Decomposition (EDMD)}{132}{section.11.5}}
\newlabel{sec:edmd}{{11.5}{132}{Extended Dynamical Mode Decomposition (EDMD)}{section.11.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.6}Sparse Identification of Nonlinear Dynamics (SINDy)}{132}{section.11.6}}
\newlabel{sec:sindy}{{11.6}{132}{Sparse Identification of Nonlinear Dynamics (SINDy)}{section.11.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.7}DMD with Irregularly Sampled Timesteps}{132}{section.11.7}}
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Exploratory Data Analysis}{133}{chapter.12}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@12}}
\ttl@writefile{ptc}{\ttl@starttoc{default@13}}
\@writefile{toc}{\contentsline {section}{\numberline {12.1}Basic Steps}{133}{section.12.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1.1}Import, Clean, Data Census}{133}{subsection.12.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1.2}Single Variable Explorations}{133}{subsection.12.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1.3}Pair-wise Explorations}{133}{subsection.12.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1.4}Multivariate Analysis}{133}{subsection.12.1.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1.5}Estimation and Hypothesis Testing}{133}{subsection.12.1.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1.6}Visualization}{133}{subsection.12.1.6}}
\citation{athey2016generalized}
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Causality}{135}{chapter.13}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@13}}
\ttl@writefile{ptc}{\ttl@starttoc{default@14}}
\@writefile{toc}{\contentsline {section}{\numberline {13.1}Generalized Random Forests}{135}{section.13.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {14}Machine Learning}{137}{chapter.14}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@14}}
\ttl@writefile{ptc}{\ttl@starttoc{default@15}}
\newlabel{chp:machinelearning}{{14}{137}{Machine Learning}{chapter.14}{}}
\bibstyle{agsm}
\bibdata{references}
\@writefile{toc}{\contentsline {chapter}{\numberline {15}Algorithms}{139}{chapter.15}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{default@15}}
\ttl@writefile{ptc}{\ttl@starttoc{default@16}}
\@writefile{lof}{\contentsline {figure}{\numberline {15.1}{\ignorespaces Common time complexities for algorithms.}}{140}{figure.15.1}}
\newlabel{fig:algorithms_time_complexity}{{15.1}{140}{Common time complexities for algorithms}{figure.15.1}{}}
\harvardcite{amoeba2015svdpca}{amoeba}{amoeba}{2015}
\harvardcite{athey2016generalized}{Athey, Tibshirani \harvardand \^^MWager}{Athey et~al.}{2016}
\harvardcite{barnesmatrixdiff}{Barnes}{Barnes}{n/a}
\harvardcite{stanfordaxiomofchoice}{Bell}{Bell}{2015}
\harvardcite{blitzstein2019introduction}{Blitzstein \harvardand \ Hwang}{Blitzstein \harvardand \ Hwang}{2019}
\harvardcite{bogart2004combinatorics}{Bogart}{Bogart}{2004}
\harvardcite{stanfordsetnotation}{Bradley}{Bradley}{n/a}
\harvardcite{brooks2012pcal1}{Brooks \harvardand \ Jot}{Brooks \harvardand \ Jot}{n.d.}
\harvardcite{brooks2014pure}{Brooks, Dul{\'a} \harvardand \^^MBoone}{Brooks et~al.}{2013}
\harvardcite{stevebrunton}{Brunton}{Brunton}{n/a}
\harvardcite{morningpaper2019nnmf}{Colyer}{Colyer}{2019}
\harvardcite{cvitanovic2016chaos}{Cvitanovic, Artuso, Mainieri, Tanner \harvardand \ Vattay}{Cvitanovic et~al.}{2016}
\harvardcite{damask2019consistently}{Damask}{Damask}{2019}
\harvardcite{friedman2001elements}{Friedman, Hastie \harvardand \^^MTibshirani}{Friedman et~al.}{2001}
\harvardcite{gavish2013optimal}{Gavish \harvardand \ Donoho}{Gavish \harvardand \ Donoho}{2013}
\harvardcite{rgeraNotes}{Gera}{Gera}{2009}
\harvardcite{gillis2014nonnegative}{Gillis}{Gillis}{2014}
\harvardcite{hastie2015matrix}{Hastie, Mazumder, Lee \harvardand \^^MZadeh}{Hastie et~al.}{2015}
\harvardcite{kronenburg2011binomial}{Kronenburg}{Kronenburg}{2011}
\harvardcite{lindgren2006lectures}{Lindgren}{Lindgren}{2006}
\harvardcite{mathworkseig}{Mathworks}{Mathworks}{n/a}
\ttl@writefile{ptc}{\ttl@stoptoc{default@16}}
\ttl@writefile{ptc}{\ttl@starttoc{default@17}}
\harvardcite{mazumder2010spectral}{Mazumder, Hastie \harvardand \^^MTibshirani}{Mazumder et~al.}{2010}
\harvardcite{megretski2004pod}{Megretski}{Megretski}{2004}
\harvardcite{rodriguez2007generalized}{Rodriguez}{Rodriguez}{2007}
\harvardcite{salova2019koopman}{Salova, Emenheiser, Rupe, Crutchfield \harvardand \^^MDSouza}{Salova et~al.}{2019}
\harvardcite{ncssridgeregression}{Software}{Software}{n/a}
\harvardcite{brightsideofmathematics}{The Bright Side~of Mathematics}{The Bright Side~of Mathematics}{2019}
\harvardcite{wasserman2013all}{Wasserman}{Wasserman}{2013}
\harvardcite{wilf2013generating}{Wilf}{Wilf}{2013}
\ttl@finishall
